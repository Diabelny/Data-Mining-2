{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and utilities\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,RepeatedStratifiedKFold, RandomizedSearchCV,GridSearchCV, RepeatedKFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.knn import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"../Dataset_prepared/Prepared_train.csv\")\n",
    "df_test=pd.read_csv(\"../Dataset_prepared/Prepared_test.csv\")\n",
    "\n",
    "df_train.drop('actor',axis=1,inplace=True)\n",
    "df_train.drop('filename',axis=1,inplace=True)\n",
    "\n",
    "df_test.drop('actor',axis=1,inplace=True)\n",
    "df_test.drop('filename',axis=1,inplace=True)\n",
    "\n",
    "# Label encoding for train and test\n",
    "le=preprocessing.LabelEncoder()\n",
    "c = df_train.select_dtypes(include=['object']).columns.tolist()\n",
    "for i in c:\n",
    "    df_train[i]=le.fit_transform(df_train[i])\n",
    "for i in c:\n",
    "    df_test[i]=le.fit_transform(df_test[i])\n",
    "\n",
    "# Normalization of train and test\n",
    "scaler = StandardScaler()\n",
    "numeric_features = [n for n in df_train.columns if n!=\"emotion\" and n!= \"vocal_channel\" and n!= \"emotional_intensity\" and n!= \"statement\" and n!= \"repetition\" and n!= \"sex\" and n!=\"filename\" and n!=\"actor\"]\n",
    "scaled_features = scaler.fit_transform(df_train[numeric_features])\n",
    "df_train[numeric_features] = scaled_features\n",
    "scaled_features_test = scaler.transform(df_test[numeric_features])\n",
    "df_test[numeric_features] = scaled_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocal_channel</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotional_intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repetition</th>\n",
       "      <th>sex</th>\n",
       "      <th>mean</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>...</th>\n",
       "      <th>sc_skew_w4</th>\n",
       "      <th>stft_sum_w4</th>\n",
       "      <th>stft_q01_w4</th>\n",
       "      <th>stft_q05_w4</th>\n",
       "      <th>stft_q25_w4</th>\n",
       "      <th>stft_q50_w4</th>\n",
       "      <th>stft_q75_w4</th>\n",
       "      <th>stft_q95_w4</th>\n",
       "      <th>stft_kur_w4</th>\n",
       "      <th>stft_skew_w4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018034</td>\n",
       "      <td>0.603864</td>\n",
       "      <td>-0.063106</td>\n",
       "      <td>-0.7693</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.354785</td>\n",
       "      <td>0.161158</td>\n",
       "      <td>-0.925138</td>\n",
       "      <td>2.167997</td>\n",
       "      <td>1.515260</td>\n",
       "      <td>1.079945</td>\n",
       "      <td>0.690192</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>9.400360</td>\n",
       "      <td>-3.035005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>0.603864</td>\n",
       "      <td>-0.063106</td>\n",
       "      <td>-0.7693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.659640</td>\n",
       "      <td>-0.173413</td>\n",
       "      <td>1.908839</td>\n",
       "      <td>1.610931</td>\n",
       "      <td>0.996435</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>0.409754</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>-0.186504</td>\n",
       "      <td>0.434538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018855</td>\n",
       "      <td>0.622665</td>\n",
       "      <td>-0.063106</td>\n",
       "      <td>-0.7693</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.086640</td>\n",
       "      <td>-0.286208</td>\n",
       "      <td>-0.925138</td>\n",
       "      <td>1.285119</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>0.877776</td>\n",
       "      <td>0.722854</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>2.891302</td>\n",
       "      <td>-1.463754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>0.603864</td>\n",
       "      <td>-0.063106</td>\n",
       "      <td>-0.7693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396009</td>\n",
       "      <td>-0.588962</td>\n",
       "      <td>1.429546</td>\n",
       "      <td>1.176485</td>\n",
       "      <td>0.899140</td>\n",
       "      <td>0.723117</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>-0.049566</td>\n",
       "      <td>-0.052845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015921</td>\n",
       "      <td>0.603864</td>\n",
       "      <td>-0.063106</td>\n",
       "      <td>-0.7693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.624456</td>\n",
       "      <td>0.170902</td>\n",
       "      <td>0.987370</td>\n",
       "      <td>1.346235</td>\n",
       "      <td>1.065980</td>\n",
       "      <td>0.761301</td>\n",
       "      <td>0.452031</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>0.878701</td>\n",
       "      <td>-0.532241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vocal_channel  emotion  emotional_intensity  statement  repetition  sex  \\\n",
       "0              1        5                    0          1           0    1   \n",
       "1              1        5                    0          1           1    1   \n",
       "2              1        5                    0          0           0    1   \n",
       "3              1        5                    0          0           1    1   \n",
       "4              1        1                    0          1           0    1   \n",
       "\n",
       "       mean       q25       q50     q75  ...  sc_skew_w4  stft_sum_w4  \\\n",
       "0  0.018034  0.603864 -0.063106 -0.7693  ...   -4.354785     0.161158   \n",
       "1  0.013950  0.603864 -0.063106 -0.7693  ...   -0.659640    -0.173413   \n",
       "2  0.018855  0.622665 -0.063106 -0.7693  ...   -3.086640    -0.286208   \n",
       "3  0.018087  0.603864 -0.063106 -0.7693  ...   -0.396009    -0.588962   \n",
       "4  0.015921  0.603864 -0.063106 -0.7693  ...   -0.624456     0.170902   \n",
       "\n",
       "   stft_q01_w4  stft_q05_w4  stft_q25_w4  stft_q50_w4  stft_q75_w4  \\\n",
       "0    -0.925138     2.167997     1.515260     1.079945     0.690192   \n",
       "1     1.908839     1.610931     0.996435     0.639413     0.409754   \n",
       "2    -0.925138     1.285119     1.118715     0.877776     0.722854   \n",
       "3     1.429546     1.176485     0.899140     0.723117     0.560400   \n",
       "4     0.987370     1.346235     1.065980     0.761301     0.452031   \n",
       "\n",
       "   stft_q95_w4  stft_kur_w4  stft_skew_w4  \n",
       "0     0.036057     9.400360     -3.035005  \n",
       "1     0.036057    -0.186504      0.434538  \n",
       "2     0.036057     2.891302     -1.463754  \n",
       "3     0.036057    -0.049566     -0.052845  \n",
       "4     0.036057     0.878701     -0.532241  \n",
       "\n",
       "[5 rows x 259 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_train.values\n",
    "test=df_test.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we experiments different technics to detect Outliers belonging to different families:\n",
    "- Density-based approach (LOF,DBSCAN)\n",
    "- Distance-Based approach (KNN)\n",
    "- Angle-Based approach (ABOD)\n",
    "- Model-based approach (Isolation Forest) \n",
    "\n",
    "After detecting all outliers  we analyze each set returned from the different approach and try to compare them quantitatively.\n",
    "We will do some scatter plots in 2/3D to see how they are distributed with the Inliers\n",
    "We will intersect the 1% otuliers detected  among the the different sets returned by each approach.\n",
    "We will intersect the top 10 outliers detected, for a better comparison, among the different sets returned by each approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desnity-based approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance-based approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angle-based approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABOD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ISOLATION FOREST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
