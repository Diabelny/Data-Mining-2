{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold,RepeatedStratifiedKFold, RandomizedSearchCV,GridSearchCV, RepeatedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "from scikitplot.metrics import plot_precision_recall, plot_roc, plot_cumulative_gain, plot_lift_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read datasets\n",
    "df_train=pd.read_csv(\"../Dataset_prepared/Prepared_train.csv\")\n",
    "df_test=pd.read_csv(\"../Dataset_prepared/Prepared_test.csv\")\n",
    "\n",
    "#Drop useless features\n",
    "df_train.drop('actor',axis=1,inplace=True)\n",
    "df_train.drop('filename',axis=1,inplace=True)\n",
    "df_test.drop('actor',axis=1,inplace=True)\n",
    "df_test.drop('filename',axis=1,inplace=True)\n",
    "\n",
    "#LabelEncode categorical features\n",
    "le=preprocessing.LabelEncoder()\n",
    "c = df_train.select_dtypes(include=['object']).columns.tolist()\n",
    "for i in c:\n",
    "    df_train[i]=le.fit_transform(df_train[i])\n",
    "\n",
    "for i in c:\n",
    "    df_test[i]=le.fit_transform(df_test[i])\n",
    "\n",
    "#Normalize pure numeric features \n",
    "scaler = StandardScaler()\n",
    "numeric_features = [n for n in df_train.columns if n!=\"emotion\" and n!= \"vocal_channel\" and n!= \"emotional_intensity\" and n!= \"statement\" and n!= \"repetition\" and n!= \"sex\" and n!=\"filename\" and n!=\"actor\"]\n",
    "scaled_features = scaler.fit_transform(df_train[numeric_features])\n",
    "df_train[numeric_features] = scaled_features\n",
    "scaled_features_test = scaler.transform(df_test[numeric_features])\n",
    "df_test[numeric_features] = scaled_features_test\n",
    "\n",
    "#Set X_train,y_train = data to fit models. Set X_test,y_test = data to test models.\n",
    "col=[x for x in df_train.columns if x!=\"emotion\"]\n",
    "X_train=df_train[col].values\n",
    "y_train = np.array(df_train[\"emotion\"])\n",
    "X_test=df_test[col].values\n",
    "y_test = np.array(df_test[\"emotion\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential # sequential networks= all the layers are one after the others\n",
    "from keras.layers import Dense # we have flat layes \n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "# I modelli in keras sono definiti come una sequenza di livelli. \n",
    "# 1) Quindi creiamo un \"Sequential model\" e aggiungiamo i livelli uno alla volta\n",
    "# 2) Nel primo livello dobbiamo inserire il numero di feature. Quindi assegnamo all'argomento \"input_dim\" \n",
    "# il numero di features da utilizzare\n",
    "# Come configurare il numero di livelli e nodi in una NN\n",
    "# https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/\n",
    "# 3) Utilizzamo una rete fully-connected, usando la classe \"Dense\"\n",
    "# 4) Possiamo specificare il numero di neuroni o nodi nel livello con il primo argomento e specificare l'activation function\n",
    "# La sigmoid sull'utimo livello ci assicura che l'output sia compreso tra 0 e 1\n",
    "# 5) Durante la compilazione è necessario specificare alcune proprietà aggiuntive richieste per l'addestramento della rete\n",
    "# Specifichiamo la funzione di perdita (loss) da utilizzare per valutare l'insieme di pesi\n",
    "# \"binary_crossentropy\" è una funzione loss per classificazione binaria\n",
    "# Come scegliere le loss functions: https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "# 6) Il training del modello si svolge su epoche e ogni epoca è suddivisa in lotti (batch):\n",
    "# - Epoche: passa attraverso tutte le righe del training set\n",
    "# - Batch: uno o più campioni considerati dal modello in un'epoca priam dell'aggiornamento dei pesi\n",
    "# Differenza tra Epochs e Batch: https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three different DNN models to fit with different batch size but same epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8\n",
    "def build_model1():\n",
    "    n_feature = X_train.shape[1] # numero colonne\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=n_feature, activation='relu')) \n",
    "    model.add(Dense(64, activation='relu'))# second layer\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    # if we have multiclass u have to specify as output the number of classes\n",
    "    model.compile(loss='sparse_categorical_crossentropy', # compile=build the network. if binary classification use binary_crossentropy as loss fucntions\n",
    "                  optimizer=\"adam\", metrics=['f1_macro']) # metric u want to observe -> typically accuracy,f1 score\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8\n",
    "def build_model2():\n",
    "    n_feature = X_train.shape[1] # numero colonne\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=n_feature, activation='tanh')) \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    # if we have multiclass u have to specify as output the number of classes\n",
    "    model.compile(loss='sparse_categorical_crossentropy', # compile=build the network. if binary classification use binary_crossentropy as loss fucntions\n",
    "                  optimizer=\"adam\", metrics=['f1_macro']) # metric u want to observe -> typically accuracy,f1 score\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8\n",
    "def build_model3():\n",
    "    n_feature = X_train.shape[1] # numero colonne\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=n_feature, activation='tanh')) \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    # if we have multiclass u have to specify as output the number of classes\n",
    "    model.compile(loss='sparse_categorical_crossentropy', # compile=build the network. if binary classification use binary_crossentropy as loss fucntions\n",
    "                  optimizer=\"adam\", metrics=['f1_macro']) # metric u want to observe -> typically accuracy,f1 score\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the models with epochs=30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the models with epochs=50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the models with epochs=100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to build the best models with a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_best(meta, hidden_layer_sizes, activation):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, activation=activation))\n",
    "    model.add(keras.layers.Dense(n_classes_, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(\n",
    "    model=build_model_best,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'model__hidden_layer_sizes': [(128, 128, 128), (64, 64, 64), (32, 32, 32)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'optimizer': [\"adam\", \"sgd\"],\n",
    "    'epochs': [10, 50, 100, 200]\n",
    "}\n",
    "\n",
    "best_model = RandomizedSearchCV(clf, params, scoring='f1_macro', n_jobs=-1, verbose=True, n_iter=30, cv=3)\n",
    "best_model.fit(X_train, y_train)\n",
    "print(best_model.best_score_, best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
